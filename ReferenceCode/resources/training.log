2024-02-24 18:19:36,093 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,094 Model: "TextClassifier(
  (embeddings): TransformerDocumentEmbeddings(
    (model): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30523, 768)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0-5): 6 x TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
  )
  (decoder): Linear(in_features=768, out_features=16, bias=True)
  (dropout): Dropout(p=0.0, inplace=False)
  (locked_dropout): LockedDropout(p=0.0)
  (word_dropout): WordDropout(p=0.0)
  (loss_function): CrossEntropyLoss()
  (weights): None
  (weight_tensor) None
)"
2024-02-24 18:19:36,095 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,095 Corpus: 6246 train + 694 dev + 1735 test sentences
2024-02-24 18:19:36,095 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,096 Train:  6246 sentences
2024-02-24 18:19:36,097         (train_with_dev=False, train_with_test=False)
2024-02-24 18:19:36,097 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,098 Training Params:
2024-02-24 18:19:36,099  - learning_rate: "5e-05" 
2024-02-24 18:19:36,099  - mini_batch_size: "4"
2024-02-24 18:19:36,100  - max_epochs: "10"
2024-02-24 18:19:36,100  - shuffle: "True"
2024-02-24 18:19:36,101 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,101 Plugins:
2024-02-24 18:19:36,102  - LinearScheduler | warmup_fraction: '0.1'
2024-02-24 18:19:36,102 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,103 Final evaluation on model after last epoch (final-model.pt)
2024-02-24 18:19:36,104  - metric: "('micro avg', 'f1-score')"
2024-02-24 18:19:36,105 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,105 Computation:
2024-02-24 18:19:36,106  - compute on device: cuda:0
2024-02-24 18:19:36,107  - embedding storage: none
2024-02-24 18:19:36,107 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,108 Model training base path: "resources/taggers/question-classification-with-transformer"
2024-02-24 18:19:36,108 ----------------------------------------------------------------------------------------------------
2024-02-24 18:19:36,109 ----------------------------------------------------------------------------------------------------
2024-02-24 18:20:00,392 epoch 1 - iter 156/1562 - loss 2.60183055 - time (sec): 24.28 - samples/sec: 25.70 - lr: 0.000005 - momentum: 0.000000
2024-02-24 18:20:24,072 epoch 1 - iter 312/1562 - loss 2.50516991 - time (sec): 47.96 - samples/sec: 26.02 - lr: 0.000010 - momentum: 0.000000
2024-02-24 18:20:49,115 epoch 1 - iter 468/1562 - loss 2.45005823 - time (sec): 73.01 - samples/sec: 25.64 - lr: 0.000015 - momentum: 0.000000
2024-02-24 18:21:13,616 epoch 1 - iter 624/1562 - loss 2.36287968 - time (sec): 97.51 - samples/sec: 25.60 - lr: 0.000020 - momentum: 0.000000
2024-02-24 18:21:38,628 epoch 1 - iter 780/1562 - loss 2.27485591 - time (sec): 122.52 - samples/sec: 25.47 - lr: 0.000025 - momentum: 0.000000
2024-02-24 18:22:04,478 epoch 1 - iter 936/1562 - loss 2.18489802 - time (sec): 148.37 - samples/sec: 25.23 - lr: 0.000030 - momentum: 0.000000
2024-02-24 18:22:30,998 epoch 1 - iter 1092/1562 - loss 2.13347428 - time (sec): 174.89 - samples/sec: 24.98 - lr: 0.000035 - momentum: 0.000000
2024-02-24 18:22:57,422 epoch 1 - iter 1248/1562 - loss 2.08680509 - time (sec): 201.31 - samples/sec: 24.80 - lr: 0.000040 - momentum: 0.000000
2024-02-24 18:23:24,700 epoch 1 - iter 1404/1562 - loss 2.03879403 - time (sec): 228.59 - samples/sec: 24.57 - lr: 0.000045 - momentum: 0.000000
2024-02-24 18:23:52,179 epoch 1 - iter 1560/1562 - loss 2.00253551 - time (sec): 256.07 - samples/sec: 24.37 - lr: 0.000050 - momentum: 0.000000
2024-02-24 18:23:52,515 ----------------------------------------------------------------------------------------------------
2024-02-24 18:23:52,517 EPOCH 1 done: loss 2.0020 - lr: 0.000050
2024-02-24 18:24:20,855 DEV : loss 1.5832395553588867 - f1-score (micro avg)  0.5418
2024-02-24 18:24:39,980 ----------------------------------------------------------------------------------------------------
2024-02-24 18:25:06,263 epoch 2 - iter 156/1562 - loss 1.63355728 - time (sec): 26.28 - samples/sec: 23.74 - lr: 0.000049 - momentum: 0.000000
2024-02-24 18:25:32,690 epoch 2 - iter 312/1562 - loss 1.59066052 - time (sec): 52.71 - samples/sec: 23.68 - lr: 0.000049 - momentum: 0.000000
2024-02-24 18:26:01,211 epoch 2 - iter 468/1562 - loss 1.56078927 - time (sec): 81.23 - samples/sec: 23.05 - lr: 0.000048 - momentum: 0.000000
2024-02-24 18:26:30,716 epoch 2 - iter 624/1562 - loss 1.54341618 - time (sec): 110.73 - samples/sec: 22.54 - lr: 0.000048 - momentum: 0.000000
2024-02-24 18:26:59,651 epoch 2 - iter 780/1562 - loss 1.52971215 - time (sec): 139.67 - samples/sec: 22.34 - lr: 0.000047 - momentum: 0.000000
2024-02-24 18:27:28,866 epoch 2 - iter 936/1562 - loss 1.51524799 - time (sec): 168.88 - samples/sec: 22.17 - lr: 0.000047 - momentum: 0.000000
2024-02-24 18:27:57,927 epoch 2 - iter 1092/1562 - loss 1.51864793 - time (sec): 197.95 - samples/sec: 22.07 - lr: 0.000046 - momentum: 0.000000
2024-02-24 18:28:26,871 epoch 2 - iter 1248/1562 - loss 1.51290961 - time (sec): 226.89 - samples/sec: 22.00 - lr: 0.000046 - momentum: 0.000000
2024-02-24 18:28:55,349 epoch 2 - iter 1404/1562 - loss 1.51454609 - time (sec): 255.37 - samples/sec: 21.99 - lr: 0.000045 - momentum: 0.000000
2024-02-24 18:29:24,108 epoch 2 - iter 1560/1562 - loss 1.51047707 - time (sec): 284.13 - samples/sec: 21.96 - lr: 0.000044 - momentum: 0.000000
2024-02-24 18:29:24,414 ----------------------------------------------------------------------------------------------------
2024-02-24 18:29:24,415 EPOCH 2 done: loss 1.5116 - lr: 0.000044
2024-02-24 18:29:52,586 DEV : loss 1.5166486501693726 - f1-score (micro avg)  0.5591
2024-02-24 18:30:06,719 ----------------------------------------------------------------------------------------------------
2024-02-24 18:30:33,140 epoch 3 - iter 156/1562 - loss 1.24978475 - time (sec): 26.42 - samples/sec: 23.62 - lr: 0.000044 - momentum: 0.000000
2024-02-24 18:31:00,103 epoch 3 - iter 312/1562 - loss 1.25215935 - time (sec): 53.38 - samples/sec: 23.38 - lr: 0.000043 - momentum: 0.000000
2024-02-24 18:31:27,837 epoch 3 - iter 468/1562 - loss 1.22820796 - time (sec): 81.12 - samples/sec: 23.08 - lr: 0.000043 - momentum: 0.000000
2024-02-24 18:31:58,810 epoch 3 - iter 624/1562 - loss 1.20873397 - time (sec): 112.09 - samples/sec: 22.27 - lr: 0.000042 - momentum: 0.000000
2024-02-24 18:32:27,543 epoch 3 - iter 780/1562 - loss 1.19533881 - time (sec): 140.82 - samples/sec: 22.16 - lr: 0.000042 - momentum: 0.000000
2024-02-24 18:32:56,542 epoch 3 - iter 936/1562 - loss 1.20442060 - time (sec): 169.82 - samples/sec: 22.05 - lr: 0.000041 - momentum: 0.000000
2024-02-24 18:33:25,564 epoch 3 - iter 1092/1562 - loss 1.21978747 - time (sec): 198.84 - samples/sec: 21.97 - lr: 0.000041 - momentum: 0.000000
2024-02-24 18:33:57,325 epoch 3 - iter 1248/1562 - loss 1.21773328 - time (sec): 230.60 - samples/sec: 21.65 - lr: 0.000040 - momentum: 0.000000
2024-02-24 18:34:26,502 epoch 3 - iter 1404/1562 - loss 1.21762834 - time (sec): 259.78 - samples/sec: 21.62 - lr: 0.000039 - momentum: 0.000000
2024-02-24 18:34:55,469 epoch 3 - iter 1560/1562 - loss 1.20106745 - time (sec): 288.75 - samples/sec: 21.61 - lr: 0.000039 - momentum: 0.000000
2024-02-24 18:34:55,752 ----------------------------------------------------------------------------------------------------
2024-02-24 18:34:55,753 EPOCH 3 done: loss 1.2003 - lr: 0.000039
2024-02-24 18:35:24,025 DEV : loss 1.5787001848220825 - f1-score (micro avg)  0.585
2024-02-24 18:35:38,111 ----------------------------------------------------------------------------------------------------
2024-02-24 18:36:04,377 epoch 4 - iter 156/1562 - loss 0.76832876 - time (sec): 26.26 - samples/sec: 23.76 - lr: 0.000038 - momentum: 0.000000
2024-02-24 18:36:31,766 epoch 4 - iter 312/1562 - loss 0.79586978 - time (sec): 53.65 - samples/sec: 23.26 - lr: 0.000038 - momentum: 0.000000
2024-02-24 18:37:00,153 epoch 4 - iter 468/1562 - loss 0.82844341 - time (sec): 82.04 - samples/sec: 22.82 - lr: 0.000037 - momentum: 0.000000
2024-02-24 18:37:29,467 epoch 4 - iter 624/1562 - loss 0.84711667 - time (sec): 111.35 - samples/sec: 22.41 - lr: 0.000037 - momentum: 0.000000
2024-02-24 18:37:58,606 epoch 4 - iter 780/1562 - loss 0.85424398 - time (sec): 140.49 - samples/sec: 22.21 - lr: 0.000036 - momentum: 0.000000
2024-02-24 18:38:27,451 epoch 4 - iter 936/1562 - loss 0.86304352 - time (sec): 169.34 - samples/sec: 22.11 - lr: 0.000036 - momentum: 0.000000
2024-02-24 18:38:56,802 epoch 4 - iter 1092/1562 - loss 0.85269503 - time (sec): 198.69 - samples/sec: 21.98 - lr: 0.000035 - momentum: 0.000000
2024-02-24 18:39:25,618 epoch 4 - iter 1248/1562 - loss 0.85328456 - time (sec): 227.51 - samples/sec: 21.94 - lr: 0.000034 - momentum: 0.000000
2024-02-24 18:39:54,379 epoch 4 - iter 1404/1562 - loss 0.86735463 - time (sec): 256.27 - samples/sec: 21.91 - lr: 0.000034 - momentum: 0.000000
2024-02-24 18:40:24,023 epoch 4 - iter 1560/1562 - loss 0.86846990 - time (sec): 285.91 - samples/sec: 21.83 - lr: 0.000033 - momentum: 0.000000
2024-02-24 18:40:24,333 ----------------------------------------------------------------------------------------------------
2024-02-24 18:40:24,334 EPOCH 4 done: loss 0.8685 - lr: 0.000033
2024-02-24 18:40:52,608 DEV : loss 1.9956300258636475 - f1-score (micro avg)  0.5778
2024-02-24 18:41:06,615 ----------------------------------------------------------------------------------------------------
2024-02-24 18:41:33,050 epoch 5 - iter 156/1562 - loss 0.51747296 - time (sec): 26.43 - samples/sec: 23.61 - lr: 0.000033 - momentum: 0.000000
2024-02-24 18:42:00,019 epoch 5 - iter 312/1562 - loss 0.48718638 - time (sec): 53.40 - samples/sec: 23.37 - lr: 0.000032 - momentum: 0.000000
2024-02-24 18:42:28,561 epoch 5 - iter 468/1562 - loss 0.52198384 - time (sec): 81.94 - samples/sec: 22.84 - lr: 0.000032 - momentum: 0.000000
2024-02-24 18:42:57,140 epoch 5 - iter 624/1562 - loss 0.54365855 - time (sec): 110.52 - samples/sec: 22.58 - lr: 0.000031 - momentum: 0.000000
2024-02-24 18:43:25,981 epoch 5 - iter 780/1562 - loss 0.56002617 - time (sec): 139.36 - samples/sec: 22.39 - lr: 0.000031 - momentum: 0.000000
2024-02-24 18:43:55,189 epoch 5 - iter 936/1562 - loss 0.55965801 - time (sec): 168.57 - samples/sec: 22.21 - lr: 0.000030 - momentum: 0.000000
2024-02-24 18:44:23,689 epoch 5 - iter 1092/1562 - loss 0.57108601 - time (sec): 197.07 - samples/sec: 22.16 - lr: 0.000029 - momentum: 0.000000
2024-02-24 18:44:52,858 epoch 5 - iter 1248/1562 - loss 0.57139808 - time (sec): 226.24 - samples/sec: 22.06 - lr: 0.000029 - momentum: 0.000000
2024-02-24 18:45:21,781 epoch 5 - iter 1404/1562 - loss 0.57573486 - time (sec): 255.16 - samples/sec: 22.01 - lr: 0.000028 - momentum: 0.000000
2024-02-24 18:45:52,957 epoch 5 - iter 1560/1562 - loss 0.57413420 - time (sec): 286.34 - samples/sec: 21.79 - lr: 0.000028 - momentum: 0.000000
2024-02-24 18:45:53,286 ----------------------------------------------------------------------------------------------------
2024-02-24 18:45:53,287 EPOCH 5 done: loss 0.5752 - lr: 0.000028
2024-02-24 18:46:23,068 DEV : loss 2.3920891284942627 - f1-score (micro avg)  0.5677
2024-02-24 18:46:35,298 ----------------------------------------------------------------------------------------------------
2024-02-24 18:47:01,991 epoch 6 - iter 156/1562 - loss 0.28336037 - time (sec): 26.69 - samples/sec: 23.38 - lr: 0.000027 - momentum: 0.000000
2024-02-24 18:47:29,222 epoch 6 - iter 312/1562 - loss 0.31289778 - time (sec): 53.92 - samples/sec: 23.14 - lr: 0.000027 - momentum: 0.000000
2024-02-24 18:47:57,680 epoch 6 - iter 468/1562 - loss 0.35135069 - time (sec): 82.38 - samples/sec: 22.72 - lr: 0.000026 - momentum: 0.000000
2024-02-24 18:48:27,483 epoch 6 - iter 624/1562 - loss 0.34739991 - time (sec): 112.18 - samples/sec: 22.25 - lr: 0.000026 - momentum: 0.000000
2024-02-24 18:48:56,255 epoch 6 - iter 780/1562 - loss 0.32823065 - time (sec): 140.96 - samples/sec: 22.13 - lr: 0.000025 - momentum: 0.000000
2024-02-24 18:49:25,318 epoch 6 - iter 936/1562 - loss 0.32743323 - time (sec): 170.02 - samples/sec: 22.02 - lr: 0.000024 - momentum: 0.000000
2024-02-24 18:49:54,408 epoch 6 - iter 1092/1562 - loss 0.34444252 - time (sec): 199.11 - samples/sec: 21.94 - lr: 0.000024 - momentum: 0.000000
2024-02-24 18:50:23,694 epoch 6 - iter 1248/1562 - loss 0.33324239 - time (sec): 228.39 - samples/sec: 21.86 - lr: 0.000023 - momentum: 0.000000
2024-02-24 18:50:53,057 epoch 6 - iter 1404/1562 - loss 0.32234094 - time (sec): 257.76 - samples/sec: 21.79 - lr: 0.000023 - momentum: 0.000000
2024-02-24 18:51:22,605 epoch 6 - iter 1560/1562 - loss 0.32596031 - time (sec): 287.31 - samples/sec: 21.72 - lr: 0.000022 - momentum: 0.000000
2024-02-24 18:51:22,884 ----------------------------------------------------------------------------------------------------
2024-02-24 18:51:22,885 EPOCH 6 done: loss 0.3256 - lr: 0.000022
2024-02-24 18:51:51,393 DEV : loss 3.3177449703216553 - f1-score (micro avg)  0.5504
2024-02-24 18:52:04,865 ----------------------------------------------------------------------------------------------------
2024-02-24 18:52:31,316 epoch 7 - iter 156/1562 - loss 0.17530130 - time (sec): 26.45 - samples/sec: 23.59 - lr: 0.000022 - momentum: 0.000000
2024-02-24 18:52:58,544 epoch 7 - iter 312/1562 - loss 0.16805702 - time (sec): 53.68 - samples/sec: 23.25 - lr: 0.000021 - momentum: 0.000000
2024-02-24 18:53:26,941 epoch 7 - iter 468/1562 - loss 0.19278311 - time (sec): 82.07 - samples/sec: 22.81 - lr: 0.000021 - momentum: 0.000000
2024-02-24 18:53:55,133 epoch 7 - iter 624/1562 - loss 0.18378494 - time (sec): 110.27 - samples/sec: 22.64 - lr: 0.000020 - momentum: 0.000000
2024-02-24 18:54:23,738 epoch 7 - iter 780/1562 - loss 0.18857161 - time (sec): 138.87 - samples/sec: 22.47 - lr: 0.000019 - momentum: 0.000000
2024-02-24 18:54:52,515 epoch 7 - iter 936/1562 - loss 0.18392099 - time (sec): 167.65 - samples/sec: 22.33 - lr: 0.000019 - momentum: 0.000000
2024-02-24 18:55:21,516 epoch 7 - iter 1092/1562 - loss 0.18164317 - time (sec): 196.65 - samples/sec: 22.21 - lr: 0.000018 - momentum: 0.000000
2024-02-24 18:55:50,753 epoch 7 - iter 1248/1562 - loss 0.17492982 - time (sec): 225.89 - samples/sec: 22.10 - lr: 0.000018 - momentum: 0.000000
2024-02-24 18:56:19,820 epoch 7 - iter 1404/1562 - loss 0.17643357 - time (sec): 254.95 - samples/sec: 22.03 - lr: 0.000017 - momentum: 0.000000
2024-02-24 18:56:49,290 epoch 7 - iter 1560/1562 - loss 0.17476525 - time (sec): 284.42 - samples/sec: 21.94 - lr: 0.000017 - momentum: 0.000000
2024-02-24 18:56:49,571 ----------------------------------------------------------------------------------------------------
2024-02-24 18:56:49,572 EPOCH 7 done: loss 0.1746 - lr: 0.000017
2024-02-24 18:57:18,289 DEV : loss 3.8546335697174072 - f1-score (micro avg)  0.5548
2024-02-24 18:57:30,663 ----------------------------------------------------------------------------------------------------
2024-02-24 18:57:57,649 epoch 8 - iter 156/1562 - loss 0.06854232 - time (sec): 26.98 - samples/sec: 23.12 - lr: 0.000016 - momentum: 0.000000
2024-02-24 18:58:25,098 epoch 8 - iter 312/1562 - loss 0.07559528 - time (sec): 54.43 - samples/sec: 22.93 - lr: 0.000016 - momentum: 0.000000
2024-02-24 18:58:53,735 epoch 8 - iter 468/1562 - loss 0.06748397 - time (sec): 83.07 - samples/sec: 22.54 - lr: 0.000015 - momentum: 0.000000
2024-02-24 18:59:22,902 epoch 8 - iter 624/1562 - loss 0.07352181 - time (sec): 112.24 - samples/sec: 22.24 - lr: 0.000014 - momentum: 0.000000
2024-02-24 18:59:52,289 epoch 8 - iter 780/1562 - loss 0.07933832 - time (sec): 141.62 - samples/sec: 22.03 - lr: 0.000014 - momentum: 0.000000
2024-02-24 19:00:22,032 epoch 8 - iter 936/1562 - loss 0.07861745 - time (sec): 171.37 - samples/sec: 21.85 - lr: 0.000013 - momentum: 0.000000
2024-02-24 19:00:51,774 epoch 8 - iter 1092/1562 - loss 0.08014201 - time (sec): 201.11 - samples/sec: 21.72 - lr: 0.000013 - momentum: 0.000000
2024-02-24 19:01:21,139 epoch 8 - iter 1248/1562 - loss 0.07776382 - time (sec): 230.47 - samples/sec: 21.66 - lr: 0.000012 - momentum: 0.000000
2024-02-24 19:01:50,636 epoch 8 - iter 1404/1562 - loss 0.07564872 - time (sec): 259.97 - samples/sec: 21.60 - lr: 0.000012 - momentum: 0.000000
2024-02-24 19:02:20,087 epoch 8 - iter 1560/1562 - loss 0.07691827 - time (sec): 289.42 - samples/sec: 21.56 - lr: 0.000011 - momentum: 0.000000
2024-02-24 19:02:20,406 ----------------------------------------------------------------------------------------------------
2024-02-24 19:02:20,407 EPOCH 8 done: loss 0.0771 - lr: 0.000011
2024-02-24 19:02:48,233 DEV : loss 3.853803873062134 - f1-score (micro avg)  0.5591
2024-02-24 19:03:01,413 ----------------------------------------------------------------------------------------------------
2024-02-24 19:03:28,354 epoch 9 - iter 156/1562 - loss 0.03950196 - time (sec): 26.94 - samples/sec: 23.16 - lr: 0.000011 - momentum: 0.000000
2024-02-24 19:03:55,383 epoch 9 - iter 312/1562 - loss 0.03580087 - time (sec): 53.97 - samples/sec: 23.12 - lr: 0.000010 - momentum: 0.000000
2024-02-24 19:04:23,946 epoch 9 - iter 468/1562 - loss 0.03560132 - time (sec): 82.53 - samples/sec: 22.68 - lr: 0.000009 - momentum: 0.000000
2024-02-24 19:04:52,833 epoch 9 - iter 624/1562 - loss 0.02877073 - time (sec): 111.42 - samples/sec: 22.40 - lr: 0.000009 - momentum: 0.000000
2024-02-24 19:05:22,437 epoch 9 - iter 780/1562 - loss 0.02500218 - time (sec): 141.02 - samples/sec: 22.12 - lr: 0.000008 - momentum: 0.000000
2024-02-24 19:05:51,544 epoch 9 - iter 936/1562 - loss 0.02287758 - time (sec): 170.13 - samples/sec: 22.01 - lr: 0.000008 - momentum: 0.000000
2024-02-24 19:06:20,998 epoch 9 - iter 1092/1562 - loss 0.02506457 - time (sec): 199.58 - samples/sec: 21.89 - lr: 0.000007 - momentum: 0.000000
2024-02-24 19:06:50,350 epoch 9 - iter 1248/1562 - loss 0.02663557 - time (sec): 228.94 - samples/sec: 21.81 - lr: 0.000007 - momentum: 0.000000
2024-02-24 19:07:20,000 epoch 9 - iter 1404/1562 - loss 0.02793544 - time (sec): 258.59 - samples/sec: 21.72 - lr: 0.000006 - momentum: 0.000000
2024-02-24 19:07:49,674 epoch 9 - iter 1560/1562 - loss 0.02980804 - time (sec): 288.26 - samples/sec: 21.65 - lr: 0.000006 - momentum: 0.000000
2024-02-24 19:07:49,994 ----------------------------------------------------------------------------------------------------
2024-02-24 19:07:49,995 EPOCH 9 done: loss 0.0298 - lr: 0.000006
2024-02-24 19:08:19,529 DEV : loss 3.9515633583068848 - f1-score (micro avg)  0.5778
2024-02-24 19:08:32,615 ----------------------------------------------------------------------------------------------------
2024-02-24 19:08:59,011 epoch 10 - iter 156/1562 - loss 0.00972751 - time (sec): 26.39 - samples/sec: 23.64 - lr: 0.000005 - momentum: 0.000000
2024-02-24 19:09:26,122 epoch 10 - iter 312/1562 - loss 0.01394965 - time (sec): 53.51 - samples/sec: 23.32 - lr: 0.000004 - momentum: 0.000000
2024-02-24 19:09:55,033 epoch 10 - iter 468/1562 - loss 0.01484381 - time (sec): 82.42 - samples/sec: 22.71 - lr: 0.000004 - momentum: 0.000000
2024-02-24 19:10:23,892 epoch 10 - iter 624/1562 - loss 0.01227328 - time (sec): 111.28 - samples/sec: 22.43 - lr: 0.000003 - momentum: 0.000000
2024-02-24 19:10:52,710 epoch 10 - iter 780/1562 - loss 0.01219938 - time (sec): 140.09 - samples/sec: 22.27 - lr: 0.000003 - momentum: 0.000000
2024-02-24 19:11:22,269 epoch 10 - iter 936/1562 - loss 0.01039881 - time (sec): 169.65 - samples/sec: 22.07 - lr: 0.000002 - momentum: 0.000000
2024-02-24 19:11:51,685 epoch 10 - iter 1092/1562 - loss 0.01118922 - time (sec): 199.07 - samples/sec: 21.94 - lr: 0.000002 - momentum: 0.000000
2024-02-24 19:12:21,471 epoch 10 - iter 1248/1562 - loss 0.01112724 - time (sec): 228.85 - samples/sec: 21.81 - lr: 0.000001 - momentum: 0.000000
2024-02-24 19:12:51,549 epoch 10 - iter 1404/1562 - loss 0.01170812 - time (sec): 258.93 - samples/sec: 21.69 - lr: 0.000001 - momentum: 0.000000
2024-02-24 19:13:21,352 epoch 10 - iter 1560/1562 - loss 0.01272065 - time (sec): 288.74 - samples/sec: 21.61 - lr: 0.000000 - momentum: 0.000000
2024-02-24 19:13:21,670 ----------------------------------------------------------------------------------------------------
2024-02-24 19:13:21,671 EPOCH 10 done: loss 0.0127 - lr: 0.000000
2024-02-24 19:13:50,129 DEV : loss 4.07877779006958 - f1-score (micro avg)  0.572
2024-02-24 19:14:04,462 ----------------------------------------------------------------------------------------------------
2024-02-24 19:14:04,464 Testing using last state of model ...
2024-02-24 19:15:13,861 
Results:
- F-score (micro) 0.5429
- F-score (macro) 0.4705
- Accuracy 0.5429

By class:
              precision    recall  f1-score   support

        INFP     0.6107    0.6189    0.6148       370
        INTP     0.5729    0.5768    0.5748       293
        INFJ     0.5142    0.5035    0.5088       288
        INTJ     0.5572    0.5803    0.5685       193
        ENTP     0.5194    0.4963    0.5076       135
        ENFP     0.5984    0.5840    0.5911       125
        ISTP     0.5000    0.4627    0.4806        67
        ISFP     0.3396    0.3396    0.3396        53
        ISFJ     0.5306    0.5778    0.5532        45
        ENTJ     0.5000    0.5000    0.5000        44
        ENFJ     0.4773    0.5122    0.4941        41
        ISTJ     0.4167    0.3409    0.3750        44
        ESTP     0.3529    0.4000    0.3750        15
        ESFP     0.1000    0.1250    0.1111         8
        ESTJ     0.3750    0.4286    0.4000         7
        ESFJ     0.5000    0.5714    0.5333         7

    accuracy                         0.5429      1735
   macro avg     0.4666    0.4761    0.4705      1735
weighted avg     0.5428    0.5429    0.5426      1735

2024-02-24 19:15:13,862 ----------------------------------------------------------------------------------------------------
